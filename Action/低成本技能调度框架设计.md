```markdown
# 低成本技能调度框架设计（Token 友好版）

> 场景：  
> - 输入：URL + 截图路径 + detect 产物（`dom/ax/controls_tree/blocks/graphs`）+ 若干技能 Skill.json + 自然语言任务描述  
> - 输出：用“尽量少的 token”让外部 LLM 选技能 + 填参数 + 给出调用计划

---

## 1. 总体原则（围绕省 token）

1. **LLM 只做一件事：规划**  
   - 不让 LLM 看原始 DOM、代码，只看“压缩后的摘要 + 少量候选技能卡片”。
2. **所有重的工作离线 / 本地做**  
   - 技能枚举、筛选、索引、DOM 分析、块划分、交互图等都在本地完成。
3. **严格控制 LLM 上下文体积**  
   - 控制：候选技能数（5–10 个）、技能卡片长度（每个 ~200 字）、页面摘要长度（整段不超过 400–600 字）。
4. **尽量复用结果，避免重复问同一问题**  
   - 块命名、技能描述、schema 抽取等结果缓存到本地，下次同站点复用。

---

## 2. 模块拆分与职责

> 所有模块尽量输出“小 JSON 结构”，供 LLM 使用时再拼接文本。

- `planner/env_summary.py`  
  - 输入：`run_dir`（detect 产物）  
  - 输出：`page_summary.json`（极简页面摘要）
    - `blocks`: 每块 `{id, selector, short_name, short_desc}`（≤ 3–5 行文字）
    - `main_block_id`: 与当前 URL / 主功能最相关的块 id（本地规则判断）。

- `planner/skill_index.py`  
  - 输入：技能根目录（扫描所有 Skill*.json）  
  - 输出：`skills_index.json`（每个技能一条卡片）
    - 只保留：`id, name, description(短), domain, selector, args_schema(简短)`  
  - 支持本地检索：BM25 / 简单关键词 / 可选 embedding（不强制）。

- `planner/llm_client.py`  
  - 封装外部 LLM / embedding 调用。限制：
    - temperature 低（0–0.3）  
    - max_tokens 合理（比如 512–1024）  
    - 统计当次 token 数，便于监控成本。

- `planner/planner.py`  
  - **唯一需要调用 LLM 的地方**：  
    - 给出：任务文本 + 页面摘要 + 少量候选技能卡片。  
    - 让 LLM 输出 JSON 计划（skill_id + args）。

- `planner/executor.py`  
  - 读取计划，用现有 `browser.invoke` 或 import `.py` 调用技能，不再询问 LLM。

---

## 3. Token 友好型流水线

### 3.1 本地预处理（不耗 LLM token）

1. **页面摘要（Env Summary）**
   - 从 `blocks.json`、`controls_tree.json`、`ax.json` 里做纯规则分析：
     - 找出与“搜索 / 表单 / 列表 / 筛选”相关的块（靠 selector / role / class 判断）。
   - 输出极短摘要：
     - 示例：
       - `blocks`:
         - `b1`: “酒店搜索模块：包含目的地/日期/住客/星级/搜索按钮”
         - `b2`: “推荐列表：酒店卡片列表”
         - `b3`: “底部导航”
       - `main_block_id`: `b1`
   - 完全不调用 LLM。

2. **技能索引 & 候选筛选**
   - 从 Skill JSON 抽取“技能卡片”（不包含 program.code）：
     - `id, name, short_desc, domain, selector, args_schema(只列参数名/类型/一句话说明)`。
   - 静态筛选：
     - 域过滤：`skill.domain == current_domain`。  
     - URL 匹配：`preconditions.url_matches` 命中当前 URL。  
     - 控件存在：`locators.selector` 在 `controls_tree` 中存在。
   - 关键词 / BM25 粗筛（不用 LLM）：
     - 查询 = 任务文本 + `page_summary.main_block`。  
     - 对技能卡片文本做 BM25 / 关键词匹配，取 top_k（5–10）。

> 至此，只用本地计算就把几十个技能压缩到 ≤10 个候选，不花 LLM token。

---

### 3.2 LLM 调度（唯一使用 LLM 的步骤）

**输入结构设计（尽量短）**

- `task_text`：原始任务（尽量保持原问题）。
- `page_summary_snippet`：只取与 main_block 相关的 2–3 行：
  - 例如：  
    - “当前页面为携程首页。”  
    - “主模块：酒店搜索模块（包含目的地/入住/退房/房间及住客/酒店级别/关键词/搜索按钮）。”
- `candidate_skills`：仅给 5–10 条，格式类似：

```text
[SKILL 1]
id: hotel_search_v1
path: /.../Skill_div_hs_list-search-container_e4Wsg_d318/Skill_...json
name: 填写酒店搜索表单
selector: #kakxi
args:
  - destination: string, 必填, 目的地城市名
  - check_in_date: date, 必填, YYYY-MM-DD
  - check_out_date: date, 必填, YYYY-MM-DD
  - rooms: int, 可选, 房间数
  - adults: int, 可选, 成人数
  - children: int, 可选, 儿童数
  - star_level: string, 可选, “二星/三星/四星/五星”
  - keyword: string, 可选, 酒店名称或区域关键词

[SKILL 2]
...
```

**Prompt 结构（极简 JSON 输出）**

- system（尽量短）：
  - “你是一个工具调度器。只选择给定技能并为其填充参数，不编写浏览器脚本。输出 JSON 计划。”
- user：
  - 附上 `task_text + page_summary_snippet + candidate_skills`，最后给出固定指令：
    - “请从上述技能中选择 1~3 个，填充参数，并输出 JSON：  
      `{"plan":[{"skill_id":..., "skill_path":..., "args":{...}, "reason": "..."}]}`。”

**控制 token 的策略**

- 候选技能数控制在 5～8 个。
- 每个技能卡片控制在 150–200 字以内。
- 页面摘要只保留与任务最相关的块/字段列表，去掉坐标/BBox 等细节。
- 合并 system+user 提示，避免多轮对话。

---

## 4. 执行与结果回流（低成本修正）

- 执行：
  - 使用 LLM 产出的 `plan`，调用对应 Skill JSON：
    - 生成 `--invoke` 调用字符串，走 `browser.invoke` 或 import 对应 `.py`。

- 若执行失败（元素找不到、参数不合法）：
  - 不把完整报错原文给 LLM，只给一个极简摘要：
    - “技能 X 执行失败：原因：找不到 selector #xxx。请在相同技能集合下重新规划。”
  - 再做一次短 prompt：
    - 不重发完整技能列表，只发 `plan + 错误摘要`，让 LLM 修正参数或换一个技能。

---

## 5. RAG 的使用方式（只放在技能检索）

如果 LLM API 支持 embedding，可以做一个非常小的 RAG 层，仅用于“候选技能筛选”：

- 文档粒度：
  - 每个 Skill 1 条文档：name/description/args_schema/selector/示例调用。
  - 每个主控件块（blocks）可选 1 条文档（块名/短描述/字段列表）。

- 检索：
  - query = `task_text + main_block_name`，获取 top_k（例如 10）。
  - 只把检索出的技能卡片送入第 3.2 步的规划 prompt，仍然控制在 5–10 条。

RAG 只在本地起索引，不改变 LLM 接口调用方式，也不会显著增加 token 消耗；只是把 BM25 换成 embedding，相似度更稳。

---

## 6. 最小 MVP（极致省 token 的版本）

1. 不搞 RAG，只用纯规则 + 关键词筛选：  
   - 用 domain/url/selector 存在性 + 关键词匹配，把技能压到 5–8 个。

2. 只实现一个 LLM 调度调用：  
   - system+user 单轮请求。  
   - 不做自动重试，先人工检查质量。

3. 页面摘要先写死模板（针对特定站点，如携程）：  
   - 如：“该页面为携程首页，主模块为酒店搜索区域，包含目的地、入住日期、退房日期、房间住客、星级、关键词和搜索按钮。”

在这个 MVP 下，每次任务只需要 **一次 LLM 调用（约 1k–2k token）**，成本非常可控；等验证效果 OK，再逐步加入自动摘要、自动重试、RAG 检索等增强能力。

```

